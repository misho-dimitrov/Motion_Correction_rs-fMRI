{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the performance of several pre-processing pipelines in terms of motion correction as measured by the root mean square of the temporal derivative of the post-processed fMRI signal (DVARS)\n",
    "\n",
    "### Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3254728/\n",
    "\n",
    "### Comparing resting state fMRI de-noising approaches using multi- and single-echo acquisitions (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0173289)  \n",
    "### An evaluation of the efficacy, reliability, and sensitivity of motion correction strategies for resting-state functional MRI (https://www.sciencedirect.com/science/article/pii/S1053811917310972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "#from scipy import stats\n",
    "#from scipy.stats import wilcoxon\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statannot import add_stat_annotation\n",
    "# from statannotations.Annotator import Annotator\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check if the ASC and TD groups differ significantly in terms of age, IQ \n",
    "# and in-scanner movement (i.e. framewise displacement - FD)\n",
    "# Participant list : \n",
    "# M005B, M007A, M008A, M010A, M013B, M014A, M015C, M016C, M020B\n",
    "# M105B, M106C, M109C, M110A, M111B, M114A, M115C, M121A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check for normality of data\n",
    "def check_norm(data):\n",
    "    # Visualise first\n",
    "    plt.hist(data\n",
    "             ,bins = 10\n",
    "            )\n",
    "    plt.show()\n",
    "    \n",
    "    k2, p = stats.normaltest(data)\n",
    "    alpha = 0.05\n",
    "\n",
    "    print('P-value = ' + '{0:.10f}'.format(p))\n",
    "\n",
    "    # null hypothesis: x comes from a normal distribution\n",
    "    if p < alpha:\n",
    "        print(\"The null hypothesis can be rejected. The sample is NOT normally distributed.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected. The sample is normally distributed.\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equality of variances\n",
    "def calc_var_equal(d1, d2):\n",
    "    v1, v2 = np.var(d1), np.var(d2)\n",
    "    if (v1 / v2) or (v2 / v1) >= 4:\n",
    "        print(\"Equality = False\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Equality = True\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for significant group differences\n",
    "def test_sign_diff(d1, norm_d1, d2, norm_d2, var_equal):\n",
    "    if norm_d1 == True and norm_d2 == True:\n",
    "        if var_equal == True:\n",
    "            print(stats.ttest_ind(a=d1, b=d2, equal_var=True))\n",
    "        # https://www.statology.org/determine-equal-or-unequal-variance/\n",
    "        else:\n",
    "            print(stats.ttest_ind(a=d1, b=d2, equal_var=False))\n",
    "    else:\n",
    "        #https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.mannwhitneyu.html\n",
    "        u, prob = mannwhitneyu(d1, d2)\n",
    "        print(\"u = {:g}\".format(u))\n",
    "        print(\"prob = {:g}\".format(prob))\n",
    "        # to get two-sided p-value:\n",
    "        two_sided_prob = 2 * prob\n",
    "        print(\"P-value = \" + str(two_sided_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "def covariate_check(factor):\n",
    "    # Get data for each group\n",
    "    td_df = factor.iloc[:9,1]\n",
    "    asc_df = factor.iloc[11:19,1]\n",
    "    \n",
    "    # Check normality of each subsample\n",
    "    norm_td = check_norm(td_df)\n",
    "    norm_asc = check_norm(asc_df)\n",
    "    \n",
    "    # Check equality of variances\n",
    "    var_equal = calc_var_equal(td_df, asc_df)\n",
    "    \n",
    "    # Test if the group differences are signifcant\n",
    "    test_sign_diff(td_df, norm_td, asc_df, norm_asc, var_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load framewise displacement (FD) data\n",
    "fd_df = pd.read_excel(r'/Users/mishodimitrov/Downloads/PhD/Analysis/Project_Uno/mean_fd_split.xlsx', sheet_name='asc_td_p', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load age data\n",
    "age_df = pd.read_excel(r'/Users/mishodimitrov/Downloads/PhD/Analysis/Project_Uno/ARB_cov_split.xlsx', sheet_name='age_asc_td_p', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IQ data\n",
    "iq_df = pd.read_excel(r'/Users/mishodimitrov/Downloads/PhD/Analysis/Project_Uno/ARB_cov_split.xlsx', sheet_name='iq_asc_td_p', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check FD\n",
    "covariate_check(fd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Age\n",
    "covariate_check(age_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check IQ\n",
    "covariate_check(iq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of DVARS values for each pipeline\n",
    "pipeline_list = []\n",
    "for n in range(12):\n",
    "        # Get a pipeline\n",
    "        pipeline = pd.read_excel(r'/Users/mishodimitrov/Downloads/PhD/Analysis/Project_Uno/ARB_QC.xlsx', sheet_name=n, #skiprows=[0], \n",
    "                                 engine='openpyxl')\n",
    "        \n",
    "        pipeline_mean = pipeline.mean()\n",
    "        \n",
    "        ## # Stack all values into a 1D vector\n",
    "        #stacked_pipeline = pipeline.stack()\n",
    "        \n",
    "        # Add to the list\n",
    "        pipeline_list.append(pipeline_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distributions\n",
    "for n in range(12):\n",
    "    plt.hist(pipeline_list[n]#, bins = 20\n",
    "            )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_names = [\n",
    " '1-echo baseline',\n",
    " '1-echo + SDC',\n",
    " '3-echo',\n",
    " '3-echo + SDC',\n",
    " '3-echo + T2s',\n",
    " '3-echo + T2s + SDC',\n",
    " '4-echo',\n",
    " '4-echo + SDC',\n",
    " '4-echo + T2s',\n",
    " '4-echo + T2s + SDC',\n",
    " '3-echo ME-ICA', \n",
    " '4-echo ME-ICA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DVARS boxplot\n",
    "# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "dvars_figure = ax.boxplot(pipeline_list, \n",
    "                          #notch=True, \n",
    "                          bootstrap=5000, \n",
    "                          showfliers=False)\n",
    "ax.set_xticklabels(pipeline_names)\n",
    "#plt.show(dvars_figure)\n",
    "plt.savefig(\"dvars.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values to avoid weird conversion..\n",
    "for i in range(len(pipeline_list)):\n",
    "    pipeline_list[i] = pd.Series(pipeline_list[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of Pandas Series objects into a Pandas DataFrame object\n",
    "pipeline_df = pd.concat(pipeline_list, axis=1)\n",
    "pipeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns so that they are labelled by the pipeline names\n",
    "pipeline_df.columns = pipeline_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the updated dataframe\n",
    "pipeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show min DVARS for each pipeline\n",
    "for i in range(pipeline_df.shape[1]):\n",
    "    print('The min for ' + pipeline_df.columns[i] + ' is = ' + str(np.min(pipeline_df.iloc[:,i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show median DVARS for each pipeline\n",
    "for i in range(pipeline_df.shape[1]):\n",
    "    print('The median for ' + pipeline_df.columns[i] + ' is = ' + str(np.median(pipeline_df.iloc[:,i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show max DVARS for each pipeline\n",
    "for i in range(pipeline_df.shape[1]):\n",
    "    print('The max for ' + pipeline_df.columns[i] + ' is = ' + str(np.max(pipeline_df.iloc[:,i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list that contains all possible pairs of pipelines WITHOUT repetitions\n",
    "combo_list = list(itertools.combinations(pipeline_names, 2))\n",
    "print(combo_list)\n",
    "# to see how many comparisons would be made:\n",
    "print(len(combo_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Mann-Whitney test to obtain p-values and correct them using FDR\n",
    "def mannwhitneyu_fdr(combo_list):\n",
    "    uncorrected_p_vals = []\n",
    "    # For each combo\n",
    "    for n in range(len(combo_list)):\n",
    "        combo_cont1 = combo_list[n][0]\n",
    "        combo_cont2 = combo_list[n][1]\n",
    "        # Perform Mann-Whitney test \n",
    "        w, p = mannwhitneyu(pipeline_df.loc[:, combo_cont1].dropna(), pipeline_df.loc[:, combo_cont2].dropna())\n",
    "        uncorrected_p_vals.append(p)\n",
    "    \n",
    "    # Correct the p-values using the FDR method\n",
    "    # and more specifically, one of the newer variations (https://www.jstor.org/stable/20441303?seq=1)\n",
    "    corrected_p_vals_extra = multipletests(uncorrected_p_vals, alpha=0.05, method='fdr_tsbky')\n",
    "    corrected_p_vals = corrected_p_vals_extra[1]\n",
    "    return uncorrected_p_vals, corrected_p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected_p_vals, corrected_p_vals = mannwhitneyu_fdr(combo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Values lower than 0.05 =\", corrected_p_vals[corrected_p_vals < 0.05])\n",
    "print(\"Their indices are \", np.nonzero(corrected_p_vals < 0.05))\n",
    "print(\"Number of significantly different pairs =\", len(corrected_p_vals[corrected_p_vals < 0.05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Values higher than 0.05 =\", corrected_p_vals[corrected_p_vals > 0.05])\n",
    "print(\"Their indices are \", np.nonzero(corrected_p_vals > 0.05))\n",
    "print(\"Number of non-significantly different pairs =\", len(corrected_p_vals[corrected_p_vals > 0.05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ns_list = list(np.nonzero(corrected_p_vals > 0.05))\n",
    "sign_list = list(np.nonzero(corrected_p_vals < 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed DVARS boxplot\n",
    "plt.rcParams[\"axes.labelsize\"] += 20\n",
    "\n",
    "# create the boxplot using seaborn instead of matplotlib\n",
    "fig, ax = plt.subplots(figsize=(27,22))\n",
    "sns.set(font_scale = 2)\n",
    "ax.tick_params(axis='both', which='both', labelsize=15)\n",
    "\n",
    "ax.xaxis.set_ticks([ind for ind in range(1, 13)])\n",
    "ax.set_xticklabels(pipeline_names, rotation=60, fontsize=25)\n",
    "ax.xaxis.labelpad = 20\n",
    "ax.set_xlabel(ax.get_xlabel(), fontdict={'weight': 'bold'})\n",
    "\n",
    "ax.yaxis.set_ticks([0, 5, 10, 15, 20])\n",
    "ax.set_yticklabels(['0', '5', '10', '15', '20'], rotation=0, fontsize=20)\n",
    "ax.set_ylim(ymax = 20)\n",
    "ax.set_ylabel(ax.get_ylabel(), fontdict={'weight': 'bold'})\n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', \n",
    "             #facecolor='wheat', \n",
    "             alpha=0.5)\n",
    "\n",
    "sb_ax = sns.boxplot(data=pipeline_df, #corr_matrix_list, \n",
    "                    order=pipeline_names, \n",
    "                    showfliers=False).set(\n",
    "    xlabel='Pipelines', \n",
    "    ylabel='DVARS'\n",
    ")\n",
    "\n",
    "\n",
    "# plot with annotations\n",
    "test_results = add_stat_annotation(ax, data=pipeline_df, order=pipeline_names,\n",
    "                                   box_pairs=[combo_list[i] for i in sign_list[0]],\n",
    "                                   perform_stat_test=False, pvalues=[corrected_p_vals[i] for i in sign_list[0]],\n",
    "                                   text_format='star',\n",
    "                                   loc='inside', \n",
    "                                   verbose=2)\n",
    "\n",
    "ax.set_title('DVARS Scores for the Pre-processing Pipelines',fontsize= 55, fontweight=\"bold\")\n",
    "\n",
    "plt.savefig(\"DVARS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
